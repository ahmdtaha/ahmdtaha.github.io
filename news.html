<!doctype html>
<html>
<head>
	<title>Ahmed Taha Home Page</title>
</head>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89530027-1', 'auto');
  ga('send', 'pageview');

</script>

  
  
  <script type="text/javascript">
	  

	  $(document).ready(function(){ 
	      $(window).scroll(function(){ 
	          if ($(this).scrollTop() > 100) { 
	              $('#scroll').fadeIn(); 
	          } else { 
	              $('#scroll').fadeOut(); 
	          } 
	      }); 
	      $('#scroll').click(function(){ 
	          $("html, body").animate({ scrollTop: 0 }, 600); 
	          return false; 
	      }); 
	  });
	  
	  
  function toggle() {
    var ls = this.parentNode.getElementsByTagName('ul')[0],
        styles, display;

    if (ls) {
      styles = window.getComputedStyle(ls);
      display = styles.getPropertyValue('display');

      ls.style.display = (display === 'none' ? 'block' : 'none');
    }
  }
  
  function afterload()
  {	
	  var eles = document.querySelectorAll('.ele');

	  Array.prototype.slice.call(eles).forEach(function (e) {
	    e.addEventListener('click', toggle);
	  });
  	
  }
  function img_clicked(ele_id) {
	  var img = document.getElementById(ele_id);
	  var modal = document.getElementById('myModal');
	  var modalImg = document.getElementById("img01");
	  var captionText = document.getElementById("caption");
	  
	  modal.style.display = "block";
	  modalImg.src = img.src;
	  captionText.innerHTML = img.alt;
	  
	  // Get the <span> element that closes the modal
	  var span = document.getElementsByClassName("close")[0];

	  // When the user clicks on <span> (x), close the modal
	  span.onclick = function() {
	    modal.style.display = "none";
	  } 
  }
  
  </script>
  
  <style>
	  
	  #scroll {
	      position:fixed;
	      right:10px;
	      bottom:10px;
	      cursor:pointer;
	      width:50px;
	      height:50px;
	      background-color:#3498db;
	      text-indent:-9999px;
	      display:none;
	      -webkit-border-radius:60px;
	      -moz-border-radius:60px;
	      border-radius:60px
	  }
	  #scroll span {
	      position:absolute;
	      top:50%;
	      left:50%;
	      margin-left:-8px;
	      margin-top:-12px;
	      height:0;
	      width:0;
	      border:8px solid transparent;
	      border-bottom-color:#ffffff;
	  }
	  #scroll:hover {
	      background-color:#e74c3c;
	      opacity:1;filter:"alpha(opacity=100)";
	      -ms-filter:"alpha(opacity=100)";
	  }
	  
	  body{
		  background: #ECE9E6;  /* fallback for old browsers */
		  background: -webkit-linear-gradient(to bottom, #FFFFFF, #ECE9E6);  /* Chrome 10-25, Safari 5.1-6 */
		  background: linear-gradient(to bottom, #FFFFFF, #ECE9E6); /* W3C, IE 10+/ Edge, Firefox 16+, Chrome 26+, Opera 12+, Safari 7+ */
		  margin-left: 10%;

		  margin-right: 10%;
	  }
	  
	  #pub_table{
	  	border-collapse: separate;
		border-spacing: 0 1px;
		margin-top: -10px;
		
	  }
	  #pub_table tr:nth-child(odd) { 
	      background-color: #ece9e6; 
	  }
	  
	  #pub_table tr:nth-child(even) { 
	      background-color: #e0dde7; 
	  }
	  
	  #pub_table td{
		  border: solid 1px #FFF;
		  border-color:transparent;
		  border-style: solid none;
		  padding: 10px;
		  //background-color: cyan;
	  }
	  #pub_table td:first-child{
		  border-left-style: solid;
		  border-top-left-radius: 10px; 
		  border-bottom-left-radius: 10px;
	  }
	  #pub_table td:last-child {
	      border-right-style: solid;
	      border-bottom-right-radius: 10px; 
	      border-top-right-radius: 10px; 
	  }
	  
	  #news_table{
		  background: #E0EAFC;  /* fallback for old browsers */
		  background: -webkit-linear-gradient(to bottom, #CFDEF3, #E0EAFC);  /* Chrome 10-25, Safari 5.1-6 */
		  background: linear-gradient(to bottom, #CFDEF3, #E0EAFC); /* W3C, IE 10+/ Edge, Firefox 16+, Chrome 26+, Opera 12+, Safari 7+ */
		  border-radius: 10px;
		  margin-left: 10%;
		  margin-right: 10%;
		  padding-top: 1px;
		  padding-bottom: 1px;
		  font-size: 18px;
	  }
	  
	  
	  #innerlinks {
	  font-family: Arial, Helvetica, sans-serif;
	  font-size: 20px;
	  letter-spacing: 0px;
	  word-spacing: 0px;
	  color: #000000;
	  font-weight: 400;
	  text-decoration: none;
	  font-style: normal;
	  font-variant: normal;
	  text-transform: none;
	  }
  
  .ele:before {
      content: "+";
      margin-right: 4px;
  }
  ul.courses {
      list-style: none;
  }
  
  ul ul {
    display: none;
  }

  .ele {
    cursor: pointer;
  }

  .ele:hover {
    color: red;
  }
  
  
  
  /* The Modal (background) */
  .modal {
      display: none; /* Hidden by default */
      position: fixed; /* Stay in place */
      z-index: 1; /* Sit on top */
      padding-top: 100px; /* Location of the box */
      left: 0;
      top: 0;
      width: 100%; /* Full width */
      height: 100%; /* Full height */
      overflow: auto; /* Enable scroll if needed */
      background-color: rgb(0,0,0); /* Fallback color */
      background-color: rgba(0,0,0,0.9); /* Black w/ opacity */
  }

  /* Modal Content (Image) */
  .modal-content {
      margin: auto;
      display: block;
      width: 80%;
      max-width: 700px;
  }

  /* Caption of Modal Image (Image Text) - Same Width as the Image */
  #caption {
      margin: auto;
      display: block;
      width: 80%;
      max-width: 700px;
      text-align: center;
      color: #ccc;
      padding: 10px 0;
      height: 150px;
  }

  /* Add Animation - Zoom in the Modal */
  .modal-content, #caption {
      animation-name: zoom;
      animation-duration: 0.6s;
  }

  @keyframes zoom {
      from {transform:scale(0)}
      to {transform:scale(1)}
  }

  /* The Close Button */
  .close {
      position: absolute;
      top: 15px;
      right: 35px;
      color: #f1f1f1;
      font-size: 40px;
      font-weight: bold;
      transition: 0.3s;
  }

  .close:hover,
  .close:focus {
      color: #bbb;
      text-decoration: none;
      cursor: pointer;
  }

  /* 100% Image Width on Smaller Screens */
  @media only screen and (max-width: 700px){
      .modal-content {
          width: 100%;
      }
  }
  
  .hover_img {
      border-radius: 5px;
      cursor: pointer;
      transition: 0.3s;
  }

  .hover_img:hover {opacity: 0.7;}
  
  
  </style>
<body onload="afterload()">
	
	<a href="#" id="scroll" style="display: inline;"><span></span></a>
	
<table align="center" border="0" cellpadding="1" cellspacing="1" style="">
	<tbody>
		<tr>
			<td><img alt="" src="./imgs/crop_image.jpg" style="width: 150px; height: 150px;border-radius: 10px;" /></td>
			<td>
			<p><span style="font-size:18px;"><span style="font-family:verdana,geneva,sans-serif;"><strong>Ahmed Taha</strong></span></span></p>

			<p><span style="font-size:18px;"><span style="font-family:verdana,geneva,sans-serif;"><strong>PhD in Computer Vision/Machine Learning</strong></span></span></p>

			<p><span style="font-size:18px;"><span style="font-family:verdana,geneva,sans-serif;"><strong></strong></span></span></p>

			<p><a href="https://github.com/ahmdtaha" target="_blank"><img alt="" src="http://cs.umd.edu/~ahmdtaha/imgs/github_32.png" title='Github'/></a>
				<a href="https://scholar.google.com/citations?user=CFIeNKEAAAAJ&hl=en" target="_blank"><img alt="" src="http://cs.umd.edu/~ahmdtaha/imgs/scholar_32.png" title='Google Scholar'/></a>
				<a href="https://www.linkedin.com/in/ahmdtaha/" target="_blank"><img alt="" src="http://cs.umd.edu/~ahmdtaha/imgs/linkedin_32.png" title='LinkedIn'/></a>
			<a href="https://www.youtube.com/channel/UCBB1d3mQc6payCzh0rmW6cA" target="_blank"><img alt="" src="http://cs.umd.edu/~ahmdtaha/imgs/youtube_32.png" title='Youtube'/></a>
			<a href="https://medium.com/@ahmdtaha" target="_blank"><img alt="" src="http://cs.umd.edu/~ahmdtaha/imgs/medium_32.png" title='Medium'/></a>
			<a href="https://www.hackerrank.com/ahmed_taha" target="_blank"><img alt="" src="http://cs.umd.edu/~ahmdtaha/imgs/hackerrank_icon_32.jpg" title='HackerRank'/></a>
			<a href="http://www.cs.umd.edu/~ahmdtaha/Ahmed_Taha_Resume.pdf" target="_blank"><img alt="" src="http://cs.umd.edu/~ahmdtaha/imgs/cv_32.png" title='Short Resume' /></a>
			<a href="http://www.cs.umd.edu/~ahmdtaha/Ahmed_Taha_CV.pdf" target="_blank"><img alt="" src="http://cs.umd.edu/~ahmdtaha/imgs/long_cv_32_2.png" title='The Long CV' /></a>
			</p>
			
			</td>
		</tr>
	</tbody>
</table>
<div id='news_table' style='width:80%'>
<p align="center" id="innerlinks">News</p>
	<ul>
		<li>[10/2023] <a href='https://www.rsipvision.com/MICCAI2023-Tuesday/13/' target="_blank">Press:</a> <i>MICCAI 2023 Magazine</i> has featured our <a href='https://arxiv.org/abs/2308.06420'>M&M Paper</a> for lesions detection in mammograms.</li>
		<li>[08/2023] <a href='https://arxiv.org/abs/2308.06420' target="_blank">Paper:</a> One Paper accepted in
			MICCAI 2023</li>
		<li>[08/2023] <a href='https://www.youtube.com/watch?v=By_O0k102PY&ab_channel=AhmedTaha' target="_blank">Video:</a> How Fully Sharded Data Parallel (FSDP) works?</li>
		<li>[07/2023] <a href='https://ahmdtaha.medium.com/big-transfer-bit-general-visual-representation-learning-cdfe1e6daf93' target="_blank">Article:</a> Big Transfer (BiT): General Visual Representation Learning</li>
		<li>[06/2023] <a href='https://medium.com/p/2a0aec52ed3d' target="_blank">Article:</a> FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</li>
		<li>[05/2023] <a href='https://medium.com/p/92db6f8803f7' target="_blank">Article:</a> High Resolution Images and Efficient Transformers</li>
		<li>[03/2023] <a href='https://medium.com/p/f00ee21e5473' target="_blank">Article:</a> Masked Autoencoders Are Scalable Vision Learners</li>
		<li>[03/2023] <b>Milestone</b>: I am glad to rejoin WhiteRabbit's research team as a research scientist.</li>
		<li>[03/2023] <b>Milestone</b>: My journey at Amazon has reached its ends.</li>
		<li>[02/2023] <a href='https://medium.com/p/c1809de2478a' target="_blank">Article:</a> Rethinking Attention with Performers - Part II & Final</li>
		<li>[10/2022] <a href='https://medium.com/p/ba6e986bf715' target="_blank">Article:</a> Rethinking Attention with Performers - Part I</li>
		<li>[10/2022] <b>Milestone</b>: I am an Applied Scientist at Amazon.</li>
		<li>[09/2022] <b>Milestone</b>: My journey at WhiteRabbit.AI has reached its end. I have been lucky to work with WhiteRabbit's research team and <a href='https://www.linkedin.com/in/nhitruongvu/'>Nhi (a.k.a. Yen Nhi)</a>. Nhi is one of my best colleagues/co-authors.</li>
		<li>[08/2022] <a href='https://arxiv.org/abs/2208.06066' target="_blank">Paper:</a> One Paper accepted in MICCAI 2022</li>
		<li>[07/2022] <a href='https://github.com/whiterabbit-ai/hct' target="_blank">Github:</a> Official PyTorch implementation of <b><i>Deep is a Luxury We Don't Have</i></b></li>
		<li>[05/2022] <a href='https://medium.com/p/b2642297927e' target="_blank">Article:</a> Understanding the Effective Receptive Field in Deep Convolutional Neural Networks</li>
		<li>[04/2022] <a href='https://medium.com/p/d3c1c088ea1b' target="_blank">Article:</a> Understanding Transfer Learning for Medical Imaging</li>
		<li>[01/2022] <a href='https://ahmdtaha.medium.com/sharpness-aware-minimization-for-efficiently-improving-generalization-9b22d89e541d' target="_blank">Article:</a> Sharpness-Aware Minimization for Efficiently Improving Generalization</li>
		<li>[12/2021] <a href='https://ahmdtaha.medium.com/feature-embedding-regularizers-svmax-vicreg-e1163b2b524e' target="_blank">Article:</a> Feature Embedding Regularizers: SVMax & VICReg</li>
		<li>[11/2021] <a href='https://ahmdtaha.medium.com/iirc-incremental-implicitly-refined-classification-23086551dca4' target="_blank">Article:</a> IIRC: Incremental Implicitly-Refined Classification</li>
		<li>[08/2021] <a href='https://ahmdtaha.medium.com/knowledge-evolution-in-neural-networks-cfdfc1510581' target="_blank">Article:</a> Knowledge Evolution in Neural Networks</li>
		<li>[07/2021] <a href='https://ahmdtaha.medium.com/cross-iteration-batch-normalization-f92ebcd677b7' target="_blank">Article:</a> Cross-Iteration Batch Normalization</li>
		<li>[07/2021] <b>Milestone</b>: I am a research scientist at WhiteRabbit.AI</li>
		<li>[05/2021] <b>Milestone</b>: My journey at the University of Maryland has reached its end; I received a Ph.D. degree in Computer Vision. I have been lucky to have both Prof <a href='https://lsd.umiacs.io/' target="_blank">Larry Davis</a> and <a href='http://www.cs.umd.edu/~abhinav/' target="_blank">Abhinav Shrivastava</a> as my Ph.D. supervisors.</li>
		<li>[05/2021] <a href='https://ahmdtaha.medium.com/l2-caf-a-neural-network-debugger-1e4f2985562c' target="_blank">Article:</a> L2-CAF: A Neural Network Debugger</li>
		<li>[04/2021] <a href='https://medium.com/p/2e2fbcc1ddf0' target="_blank">Article:</a> Deep Metric Learning Beyond Binary Supervision</li>
		<li>[03/2021] Defended my PhD dissertation &#128170; &#x1F389;&#x1F389;</li>
		<li>[03/2021] <a href='https://arxiv.org/abs/2103.05152' target="_blank">Paper:</a> One <b>Oral</b> Paper accepted in CVPR 2021</li>
		<li>[01/2021] <a href='https://medium.com/p/ce490ffdc209' target="_blank">Article:</a> Energy and Policy Considerations for Deep Learning in NLP</li>
		<li>[01/2021] <a href='https://github.com/ahmdtaha/simsiam' target="_blank">Github:</a> PyTorch implementation of <b><i>Exploring Simple Siamese Representation Learning</i></b></li>
		<li>[12/2020] <a href='https://medium.com/p/17217156f05d' target="_blank">Article:</a> Mining on Manifolds: Metric Learning without Labels</li>
		<li>[12/2020] <a href='https://github.com/ahmdtaha/tf_learning_to_count' target="_blank">Github:</a> Tensorflow implementation of <b><i>Representation Learning by Learning to Count</i></b></li>
		<li>[09/2020] <a href='https://medium.com/p/ac1f2547ed0c' target="_blank">Article:</a> A Generic Visualization Approach for Convolutional Neural Networks</li>
		<li>[08/2020] <a href='https://medium.com/p/24f4a1509248' target="_blank">Article:</a> Proxy Anchor Loss for Deep Metric Learning</li>
		<li>[08/2020] <a href='https://medium.com/p/88ec11c70696' target="_blank">Article:</a> Why Does Unsupervised Pre-training Help Deep Learning?</li>
		<li>[07/2020] <a href='https://arxiv.org/abs/2007.09748' target="_blank">Paper:</a> One Paper accepted in ECCV 2020</li>
		<li>[03/2020] <a href='https://medium.com/p/39fab3b22a47' target="_blank">Article:</a> Boosting Standard Classification Architectures Through a Ranking Regularizer</li>
		<li>[12/2019] <a href='https://arxiv.org/abs/1901.08616' target="_blank">Paper:</a> One Paper accepted in WACV 2020</li>
		<li>[11/2019] <a href='https://link.medium.com/lXX1AvGNn2' target="_blank">Article:</a> Deep Image Prior</li>
		<li>[09/2019] <a href='https://link.medium.com/BUcuZYANn2' target="_blank">Article:</a> Distilling the Knowledge in a Neural Network</li>
		<li>[06/2019] <a href='https://github.com/ahmdtaha/tf_retrieval_baseline' target="_blank">Github:</a> A Tensorflow baseline image retrieval baseline</li>
		<li>[12/2018] <a href='https://medium.com/@ahmdtaha/yet-another-imbalance-data-handling-approach-43af23f9b810' target="_blank">Article:</a> Yet Another Imbalance Data Handling Approach</li>
		<li>[11/2018] <a href='https://medium.com/@ahmdtaha/dropout-as-a-bayesian-approximation-representing-model-uncertainty-in-deep-learning-7a2e49e64a15' target="_blank">Article:</a> Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</li>
		<li>[09/2018] <a href='https://github.com/ahmdtaha/fgvr' target="_blank">Github:</a> Fine-Grained Visual Recognition Tensorflow baseline implementation</li>
		<li>[09/2018] Two Papers accepted in MICCAI 2018</li>
		<li>[08/2018] <a href='https://medium.com/@ahmdtaha/bilinear-cnn-models-for-fine-grained-visual-recognition-b25ba24d3147' target="_blank">Article:</a> Bilinear CNN Models for Fine-grained Visual Recognition</li>
		<li>[06/2018] <a href='_' target="_blank">Workshop Paper:</a> Two Stream Self-Supervised Learning for Action Recognition</li>
		<li>[09/2015] <a href='https://arxiv.org/abs/1702.00882' target="_blank">Paper:</a> Seeded Laplacian: An interactive image segmentation approach using eigenfunctions</li>
		
	</ul>
</div>
<br/>
<br/>

</body>
</html>
