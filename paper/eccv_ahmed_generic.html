<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta http-equiv="content-type" content="text/html;
      charset=windows-1252">
    <title></title>
	<style>
		td {
		   padding: 0; 
		   margin: 0;
		}
	</style>
  </head>
  <body style="background:#FFFFFF">
    <table height="100%" style='margin-top: 3rem;'>
      <tbody>
        <tr>
          <td width="10%" style="text-align: center;"> 
		  </td>
          <td style="text-align: center" >
            <h1>A Generic Visualization Approach for Convolutional Neural Networks</h1>
			<h2>ECCV 2020</h2>
              <h3 style='margin: 0px'>Ahmed Taha &nbsp;&nbsp;&nbsp;&nbsp; Xitong Yang &nbsp;&nbsp;&nbsp;&nbsp;  Abhinav Shrivastava &nbsp;&nbsp;&nbsp;&nbsp;  Larry Davis</h3>
			  <h3>University Of Maryland College Park</h3>
          </td>
          <td width="10%" style="text-align: center;"> 
			  
			  </td>
        </tr>
		
          <td width="10%"><br>
          </td>
          <td style="text-align: center">
            <a href="https://arxiv.org/abs/2007.09748" style='font-size: 1.25rem;color: #007bff;'>Arxiv</a> <b
              style="word-space:2em">&nbsp;&nbsp;</b> <a
              href="https://github.com/ahmdtaha/constrained_attention_filter" style='font-size: 1.25rem;color: #007bff;'>Github</a>
          </td>
          <td width="10%"><br>
          </td>
        </tr>
		
		<tr>			<td></td>			<td style="text-align: center" ><hr/></td>			<td></td>		</tr>        
		
		
		<tr>
			<td width="10%"><br>          </td>
			<td style="text-align: center;">
				<p style='margin: 0px;font-family: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size: 1.5rem;font-weight: 400'>Overview Video</p>
				<iframe width="800" height="450" src="https://www.youtube.com/embed/Wpw3ewSvnFE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen style='margin-top: 25px'></iframe>
			
			</td>
			<td width="10%"><br>          </td>
		</tr>

		<tr>			<td></td>			<td style="text-align: center" ><hr/></td>			<td></td>		</tr>        
		
		<tr>
          <td width="10%"><br>
          </td>
          <td style="text-align: left;">
            <h2>Abstract</h2>
            <p style='color: #212529;font-size: 1rem;color: #212529;font-family: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";'>Retrieval networks are essential for searching and indexing. Compared to classification networks, attention visualization for retrieval networks is hardly studied. We formulate attention visualization as a constrained optimization problem. We leverage the unit L2-Norm constraint as an attention filter (L2-CAF) to localize attention in both classification and retrieval networks. Unlike recent literature, our approach requires neither architectural changes nor fine-tuning. Thus, a pre-trained network's performance is never undermined
L2-CAF is quantitatively evaluated using weakly supervised object localization. State-of-the-art results are achieved on classification networks. For retrieval networks, significant improvement margins are achieved over a Grad-CAM baseline. Qualitative evaluation demonstrates how the L2-CAF visualizes attention per frame for a recurrent retrieval network. Further ablation studies highlight the computational cost of our approach and compare L2-CAF with other feasible alternatives. Code available at <a href="https://bit.ly/3iDBLFv">https://bit.ly/3iDBLFv</a>.</p></td>
          <td width="10%"><br>
          </td>
        </tr>
		
	
	<tr><td></td><td style="text-align: center" ><hr/></td><td></td></tr>        
	
	<tr><td></td>
					<td style="text-align: left;">
						            <h2>Bibtex</h2>
									<pre style="font-size:12px;background-color:#f5f5f5;padding: 9.5px;border: 1px solid #ccc;border-radius: 4px;">
@inproceedings{taha2020generic,
title={A Generic Visualization Approach for Convolutional Neural Networks},
author={Taha, Ahmed and Yang, Xitong and Shrivastava, Abhinav and Davis, Larry},
booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
year={2020}
}
									</pre>
					</td>
	<td></td></tr>
	
	<tr><td></td><td style="text-align: center" ><hr/></td><td></td></tr>        
	
	<tr><td></td>
					<td style="text-align: left;">
						            <h2>Acknowledgements</h2>
									<p style='color: #212529;font-size: 1rem;color: #212529;font-family: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";'>This  work  was  partially  funded  by  independent  grantsfrom Office of Naval Research (N000141612713) and Facebook AI
					</td>
	<td></td></tr>
		
		
      </tbody>
    </table>
  </body>
</html>
